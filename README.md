# Multi-Vendor Data Fetch Service

A production-ready Node.js service that handles asynchronous data fetching from multiple vendors with queue processing, rate limiting, and webhook support. **Built with functional programming patterns for simplicity and maintainability.**

## âœ… System Status

**All endpoints tested and working successfully!**
- âœ… Job creation and status tracking
- âœ… Sync and async vendor integration
- âœ… Rate limiting (10 requests/second per vendor)
- âœ… Data cleaning and sanitization
- âœ… Webhook processing
- âœ… Load testing (100% success rate)
- âœ… Functional code architecture (no classes)
- âœ… **Complete Postman collection with automated tests**

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Node.js 18+ (for local development)
- Postman (for API testing)

### Launch All Services

```bash
# Clone and start all services
docker compose up -d

# Verify all services are running
curl http://localhost:3000/health
curl http://localhost:3001/health  
curl http://localhost:3002/health
```

### ğŸ“® Postman Collection

Import the complete testing suite:

1. **Import Collection**: `Multi-Vendor-Data-Service.postman_collection.json`
2. **Import Environment**: `Multi-Vendor-Service.postman_environment.json`
3. **Run Tests**: Execute any folder to test specific functionality

**Collection Features**:
- ğŸ¥ **Health Checks** - Verify all services are running
- ğŸ“‹ **Job Management** - Create and track various job types
- ğŸ“Š **Status Tracking** - Monitor job progression with automated tests
- ğŸ”§ **System Monitoring** - Check metrics and performance
- âš¡ **Load Testing** - Rapid job creation scenarios
- ğŸ›¡ï¸ **Data Validation** - Verify data cleaning and normalization

### Environment Variables

Copy and configure:
```bash
cp env.example .env
# Edit .env with your settings
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server    â”‚    â”‚  Background     â”‚    â”‚   Mock Vendors  â”‚
â”‚   (Express)     â”‚    â”‚   Worker        â”‚    â”‚  (Sync/Async)   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ POST /jobs      â”‚â—„â”€â”€â–ºâ”‚ Job Processing  â”‚â—„â”€â”€â–ºâ”‚ Data APIs       â”‚
â”‚ GET /jobs/:id   â”‚    â”‚ Rate Limiting   â”‚    â”‚ Webhooks        â”‚
â”‚ POST /webhook   â”‚    â”‚ Data Cleaning   â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MongoDB      â”‚    â”‚     Redis       â”‚    â”‚    Docker       â”‚
â”‚  (Job Storage)  â”‚    â”‚   (Queue)       â”‚    â”‚  (Container)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

- **Asynchronous Job Processing**: Submit jobs and check status via REST API
- **Multiple Vendor Support**: Sync and async vendor integrations
- **Rate Limiting**: Per-vendor rate limiting (10 requests/second) with functional implementation
- **Data Cleaning**: Automatic sanitization of sensitive data
- **Webhook Support**: Async vendor callback handling
- **Queue Management**: Redis-based job queue with Bull
- **Monitoring**: Health checks, metrics, and comprehensive logging
- **Load Testing**: Built-in load testing capabilities
- **Docker Support**: Complete containerization with docker-compose
- **Functional Architecture**: Clean functional code without classes for better maintainability
- **Complete Testing Suite**: Postman collection with automated validations

## ğŸ§ª Testing with Postman

### Import Files
1. Open Postman
2. Import `Multi-Vendor-Data-Service.postman_collection.json`
3. Import `Multi-Vendor-Service.postman_environment.json`
4. Select the "Multi-Vendor Service Environment" 

### Test Scenarios

#### 1. Health Check Tests
- **API Server Health**: Validates main service is running
- **Sync Vendor Health**: Confirms sync vendor availability  
- **Async Vendor Health**: Verifies async vendor status

#### 2. Job Management Tests
- **User Profile Job**: Standard profile fetch request
- **Data Enrichment Job**: Complex customer data enhancement
- **Bulk Data Sync**: Large-scale data synchronization

#### 3. Job Status Tracking
- **Real-time Monitoring**: Check job progression (pending â†’ processing â†’ complete)
- **Error Handling**: Validate non-existent job responses
- **Timestamp Validation**: Ensure proper audit trail

#### 4. System Monitoring
- **Metrics Collection**: Validate job statistics, queue health, and system metrics
- **Performance Monitoring**: Check response times and resource usage

#### 5. Data Cleaning Validation
- **Sensitive Data Removal**: Verify password, SSN, credit card fields are removed
- **Data Normalization**: Confirm email lowercasing and phone formatting
- **Field Preservation**: Ensure non-sensitive data remains intact

#### 6. Load Testing Scenarios
- **Rapid Job Creation**: Multiple concurrent job submissions
- **Rate Limit Testing**: Validate rate limiting functionality
- **Performance Benchmarking**: Response time validation

### Environment Variables Used

| Variable | Purpose | Example |
|----------|---------|---------|
| `base_url` | API server endpoint | `http://localhost:3000` |
| `sync_vendor_url` | Sync vendor service | `http://localhost:3001` |
| `async_vendor_url` | Async vendor service | `http://localhost:3002` |
| `test_user_id` | Test user identifier | `12345` |
| `test_customer_id` | Test customer ID | `67890` |
| `mongodb_uri` | Database connection | `mongodb://admin:password@localhost:27017/vendordb` |
| `redis_url` | Redis connection | `redis://localhost:6380` |

### Running Tests

```bash
# Using Newman (Postman CLI)
npm install -g newman

# Run entire collection
newman run Multi-Vendor-Data-Service.postman_collection.json \
  -e Multi-Vendor-Service.postman_environment.json

# Run specific folder
newman run Multi-Vendor-Data-Service.postman_collection.json \
  -e Multi-Vendor-Service.postman_environment.json \
  --folder "Health Checks"
```

## API Reference

### Submit a Job

```bash
curl -X POST http://localhost:3000/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "userId": 12345,
    "action": "fetch_profile",
    "timestamp": "2024-01-01T00:00:00Z"
  }'
```

Response:
```json
{
  "request_id": "a1b2c3d4-e5f6-7890-abcd-1234567890ab"
}
```

### Check Job Status

```bash
curl http://localhost:3000/jobs/a1b2c3d4-e5f6-7890-abcd-1234567890ab
```

Response (complete):
```json
{
  "request_id": "a1b2c3d4-e5f6-7890-abcd-1234567890ab",
  "status": "complete",
  "vendor": "sync",
  "created_at": "2024-01-01T00:00:00.000Z",
  "updated_at": "2024-01-01T00:00:01.000Z",
  "processed_at": "2024-01-01T00:00:00.500Z",
  "completed_at": "2024-01-01T00:00:01.000Z",
  "result": {
    "id": 12345,
    "name": "John Doe",
    "email": "john.doe@example.com",
    "phone": "+1234567890",
    "address": "123 Main St, Anytown USA",
    "accountBalance": 25000,
    "lastLogin": "2024-01-01T00:00:00.000Z",
    "preferences": {
      "newsletter": true,
      "notifications": false
    }
  }
}
```

### System Metrics

```bash
curl http://localhost:3000/metrics
```

## Configuration

### Environment Variables

All configuration is handled through environment variables. See `env.example` for complete reference:

```bash
# Core Configuration
NODE_ENV=production
PORT=3000
MONGODB_URI=mongodb://admin:password@mongodb:27017/vendordb?authSource=admin
REDIS_URL=redis://redis:6379

# Vendor URLs
SYNC_VENDOR_URL=http://sync-vendor:3001
ASYNC_VENDOR_URL=http://async-vendor:3002
WEBHOOK_BASE_URL=http://api:3000

# Rate Limiting
RATE_LIMIT_SYNC=10
RATE_LIMIT_ASYNC=10
RATE_LIMIT_WINDOW=1000

# Queue Settings
QUEUE_CONCURRENCY=5
JOB_RETRY_ATTEMPTS=3
JOB_RETRY_DELAY=5000
```

## Job Flow

1. **Submit Job**: POST to `/jobs` with any JSON payload
2. **Queue Processing**: Job added to Redis queue, returns request_id
3. **Worker Processing**: Background worker picks up job
4. **Rate Limiting**: Check vendor-specific rate limits (functional implementation)
5. **Vendor Call**: Call appropriate vendor (sync or async)
6. **Data Processing**: Clean and sanitize response data
7. **Result Storage**: Save results to MongoDB
8. **Status Updates**: Job status progresses through states

## Job States

- `pending`: Job queued, not yet processed
- `processing`: Worker is actively processing the job
- `complete`: Job finished successfully with results
- `failed`: Job encountered an error during processing

## Functional Architecture

The entire system is built using **functional programming patterns** for better maintainability:

- **Rate Limiter**: Pure functions with closure instead of classes
- **Data Cleaning**: Functional data transformation pipeline
- **Error Handling**: Functional error boundaries
- **No Classes**: All code uses functions and modules for simplicity

Example functional rate limiter:
```javascript
const createRateLimiter = (redisClient) => {
  const checkLimit = async (vendor) => { /* ... */ };
  const waitForAvailability = async (vendor) => { /* ... */ };
  
  return { checkLimit, waitForAvailability };
};
```

## Data Cleaning Rules

The system automatically cleans vendor responses using functional transformation:

- **Trim whitespace** from all string values
- **Remove sensitive fields** containing: password, ssn, credit, secret
- **Normalize phone numbers** to +1XXXXXXXXXX format
- **Lowercase email addresses**

Example transformation:
```javascript
// Input
{
  "name": "  John Doe  ",
  "email": "JOHN.DOE@EXAMPLE.COM",
  "phone": "123-456-7890",
  "password": "secret123",
  "ssn": "123-45-6789"
}

// Output (sensitive fields removed)
{
  "name": "John Doe",
  "email": "john.doe@example.com", 
  "phone": "+11234567890"
}
```

## Load Testing

Run comprehensive load tests:

```bash
# Quick test: 10 users for 10 seconds
CONCURRENT_USERS=10 TEST_DURATION=10000 node loadtest.js

# Default: 200 users for 60 seconds
node loadtest.js

# Custom configuration
CONCURRENT_USERS=100 TEST_DURATION=30000 node loadtest.js

# Against remote server
API_URL=https://your-api.com CONCURRENT_USERS=500 node loadtest.js
```

**Recent test results (10 users, 10 seconds):**
- âœ… **100% Success Rate** (160/160 requests)
- âš¡ **30.16ms Average Response Time**
- ğŸš€ **16 Requests/Second**
- ğŸ“Š **102 Jobs Created, 15 Completed**

## Mock Vendors

### Sync Vendor (Port 3001)
- Returns data immediately with 500-2500ms processing time
- 5% error rate for testing failure scenarios
- Provides user profile data with some sensitive fields

### Async Vendor (Port 3002)
- Returns job ID immediately, processes asynchronously
- Posts results to webhook after 2-7 seconds
- 3% error rate for testing async failure handling
- Provides enhanced user data with different sensitive fields

## Development

### Local Development

```bash
# Install dependencies
npm install

# Copy environment file
cp env.example .env

# Start MongoDB and Redis (different port to avoid conflicts)
docker compose up mongodb redis -d

# Start API server
npm run dev

# Start worker (in another terminal)
npm run dev:worker

# Start mock vendors (in separate terminals)
cd vendors && node sync-vendor.js
cd vendors && node async-vendor.js
```

### Testing

```bash
# Run curl examples
./curl-examples.sh

# Import Postman collection for comprehensive testing
# Files: Multi-Vendor-Data-Service.postman_collection.json
#        Multi-Vendor-Service.postman_environment.json

# Run load tests
node loadtest.js
```

### Logging

All services use structured JSON logging:

```bash
# View API logs
docker compose logs -f api

# View worker logs  
docker compose logs -f worker

# View all logs
docker compose logs -f
```

## Monitoring

### Health Checks

```bash
curl http://localhost:3000/health
curl http://localhost:3000/metrics
```

### Postman Automated Monitoring

The Postman collection includes automated tests for:
- âœ… Response status validation
- âœ… Data structure verification
- âœ… Performance benchmarking
- âœ… Business logic validation
- âœ… Error handling verification

## Production Considerations

### Scaling
- **API Server**: Scale horizontally behind load balancer
- **Workers**: Add more worker containers for higher throughput
- **Database**: Use MongoDB replica set for high availability
- **Redis**: Use Redis Cluster for high availability

### Security
- Add authentication/authorization to API endpoints
- Use secrets management for database credentials
- Implement request validation and sanitization
- Add CORS configuration for web clients

### Performance
- Implement response caching for frequently accessed jobs
- Add database indexing for common query patterns
- Use connection pooling for database connections
- Monitor and tune rate limiting parameters

### Reliability
- Implement circuit breakers for vendor calls
- Add retry logic with exponential backoff
- Set up dead letter queues for failed jobs
- Implement graceful shutdown handling

## Troubleshooting

### Common Issues

**Services not starting:**
```bash
# Check service logs
docker compose logs api
docker compose logs worker

# Restart services
docker compose restart
```

**Database connection issues:**
```bash
# Check MongoDB logs
docker compose logs mongodb

# Verify connection
docker compose exec mongodb mongosh -u admin -p password
```

**Port conflicts:**
- Redis runs on port 6380 (instead of 6379) to avoid conflicts
- Change ports in docker-compose.yml if needed

**High error rates:**
```bash
# Check system resources
docker stats

# Monitor queue health
curl http://localhost:3000/metrics

# Use Postman collection for detailed testing
```

**Rate limiting issues:**
- The functional rate limiter is tested and working
- Adjust limits in `utils/rate-limiter.js` if needed
- Scale up vendor services for higher throughput

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ Multi-Vendor-Data-Service.postman_collection.json  # Complete API test suite
â”œâ”€â”€ Multi-Vendor-Service.postman_environment.json     # Environment variables
â”œâ”€â”€ env.example                                        # Configuration template
â”œâ”€â”€ README.md                                          # This file
â”œâ”€â”€ package.json                                       # Dependencies
â”œâ”€â”€ docker-compose.yml                                 # Container orchestration
â”œâ”€â”€ Dockerfile                                         # Container image
â”œâ”€â”€ server.js                                          # API server
â”œâ”€â”€ worker.js                                          # Background worker
â”œâ”€â”€ loadtest.js                                        # Load testing tool
â”œâ”€â”€ curl-examples.sh                                   # Quick test script
â”œâ”€â”€ models/
â”‚   â””â”€â”€ job.js                                         # Job schema
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ rate-limiter.js                               # Functional rate limiter
â””â”€â”€ vendors/
    â”œâ”€â”€ sync-vendor.js                                # Mock sync vendor
    â””â”€â”€ async-vendor.js                               # Mock async vendor
```

## License

MIT License - see LICENSE file for details 